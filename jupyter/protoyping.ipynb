{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gen3_validator\n",
    "# loading gen3 bundled jsonschema into dictionary class\n",
    "dd = gen3_validator.dict.DataDictionary('../examples/schema/json/schema_dev.json')\n",
    "dd.parse_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting list of entities\n",
    "dd.get_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f0be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning the jsonschema for a given entity\n",
    "dd.return_schema('lipidomics_file.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dictionaryutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed235b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dictionaryutils\n",
    "import json\n",
    "import yaml\n",
    "dd = dictionaryutils.DataDictionary('/Users/harrijh/projects/gen3schemadev/examples/schema/yaml')\n",
    "dd.load_data(directory='/Users/harrijh/projects/gen3schemadev/examples/schema/yaml')\n",
    "dd_resolved = dd.schema\n",
    "\n",
    "for k, v in dd_resolved.items():\n",
    "    with open(f'/Users/harrijh/projects/gen3schemadev/examples/schema/yaml/resolved/{k}.yaml', 'w') as f:\n",
    "        yaml.safe_dump(v, f)\n",
    "\n",
    "\n",
    "with open(f'/Users/harrijh/projects/gen3schemadev/examples/schema/json/gen3_bundled_schema_resolved.json', 'w') as f:\n",
    "    json.dump(dd_resolved, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68684fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = dictionaryutils.load_schemas_from_file('/Users/harrijh/projects/gen3schemadev/examples/schema/json/schema_dev.json')\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882f040",
   "metadata": {},
   "source": [
    "# To validate a gen3schemadev input yaml with the input schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930678da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install check-jsonschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b369d2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!check-jsonschema --schemafile ../src/gen3schemadev/schema/input_schema.yml ../src/gen3schemadev/schema/input_example.yml --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8c26f",
   "metadata": {},
   "source": [
    "# To validate a single gen3 schema yaml with the metaschema\n",
    "- note, the schema file needs to be resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa2150",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!check-jsonschema --schemafile ../src/gen3schemadev/schema/gen3_metaschema.yml ../examples/schema/yaml/resolved/lipidomics_file.yaml --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d32b8",
   "metadata": {},
   "source": [
    "if you give a non-resolved schema, it will not validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20608414",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!check-jsonschema --schemafile ../src/gen3schemadev/schema/gen3_metaschema.yml ../examples/schema/yaml/lipidomics_file.yaml --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee115a9e",
   "metadata": {},
   "source": [
    "# Compiling gen3schemadev input yaml to gen3 yamls\n",
    "## Steps:\n",
    "1. Validate input yaml against the input schema\n",
    "2. Load the input yaml into python dictionary\n",
    "3. The compiler should start with an empty data structure, with default values for a gen3 schema. This yaml is defined in the `src/gen3schemadev/schema/gen3_schema_template.yml`\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe1dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 16:25:47,899 [INFO] Successfully loaded YAML file: ../src/gen3schemadev/schema/gen3_metaschema.yml\n",
      "2025-10-01 16:25:47,907 [INFO] Successfully loaded YAML file: ../src/gen3schemadev/schema/gen3_metaschema.yml\n",
      "2025-10-01 16:25:47,910 [INFO] Successfully loaded YAML file: ../tests/input_example.yml\n"
     ]
    }
   ],
   "source": [
    "from gen3schemadev.schema.gen3_template import *\n",
    "from gen3schemadev.utils import *\n",
    "from gen3schemadev.schema.input_schema import DataModel\n",
    "import logging\n",
    "\n",
    "# Set up basic logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "metaschema_path = \"../src/gen3schemadev/schema/gen3_metaschema.yml\"\n",
    "converter_template = generate_gen3_template(metaschema_path)\n",
    "metaschema = load_yaml(metaschema_path)\n",
    "\n",
    "# loading input example\n",
    "data = load_yaml('../tests/input_example.yml')\n",
    "validated_model = DataModel.model_validate(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dfccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_model.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5930d",
   "metadata": {},
   "source": [
    "Now we need to read to:\n",
    "1. validate the input yaml against the input metaschema\n",
    "2. now we know the input yaml is validated, we can extract the data from the yaml into a data class which has the structure `input.entity.properties.links`\n",
    "3. We then use the data class to populated the converter template for each entity\n",
    "4. The populated templates are then written to the output directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d581f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f62327",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No properties found for entity lipidomics_file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 189\u001b[0m\n\u001b[1;32m    183\u001b[0m validated_model \u001b[38;5;241m=\u001b[39m DataModel\u001b[38;5;241m.\u001b[39mmodel_validate(data)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# links = get_entity_links('lipidomics_file', validated_model)\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# convert_entity_links(links, entity_file=True)\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# get_properties('sample', validated_model)\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# get_category('sample', validated_model)\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m out_template \u001b[38;5;241m=\u001b[39m \u001b[43mpopulate_template\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlipidomics_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidated_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverter_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m out_template\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# write_yaml(out_template, 'output.yml')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 173\u001b[0m, in \u001b[0;36mpopulate_template\u001b[0;34m(entity_name, input_data, template)\u001b[0m\n\u001b[1;32m    171\u001b[0m     output_schema[key] \u001b[38;5;241m=\u001b[39m get_category(entity_name, input_data)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 173\u001b[0m     output_schema[key] \u001b[38;5;241m=\u001b[39m \u001b[43mget_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    175\u001b[0m     links \u001b[38;5;241m=\u001b[39m get_entity_links(entity_name, input_data)\n",
      "Cell \u001b[0;32mIn[6], line 108\u001b[0m, in \u001b[0;36mget_properties\u001b[0;34m(entity_name, data)\u001b[0m\n\u001b[1;32m    106\u001b[0m         output\u001b[38;5;241m.\u001b[39mappend(pdict)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo properties found for entity \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentity_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mException\u001b[0m: No properties found for entity lipidomics_file"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "class Entity:\n",
    "    name: str\n",
    "    description: str\n",
    "    category: str\n",
    "    properties: list\n",
    "    links: list\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "def get_entity_data(entity: str, data: Any) -> Entity:\n",
    "    try:\n",
    "        for ent in data.entities:\n",
    "            if ent.name == entity:\n",
    "                return ent\n",
    "        raise ValueError(f\"Entity '{entity}' not found in data.entities\")\n",
    "    except AttributeError as e:\n",
    "        raise AttributeError(f\"Invalid data structure: {e}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred while retrieving entity data: {e}\")\n",
    "\n",
    "def get_entity_links(entity: str, data: Any) -> list[dict]:\n",
    "    links = data.links\n",
    "    entity_links = []\n",
    "    for link in links:\n",
    "        if link.child == entity:\n",
    "            entity_links.append(link.model_dump())\n",
    "    return entity_links\n",
    "\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Optional, List, Union\n",
    "\n",
    "@dataclass\n",
    "class LinkObj:\n",
    "    name: str\n",
    "    backref: str\n",
    "    label: Optional[str]\n",
    "    target_type: str\n",
    "    multiplicity: str\n",
    "    required: bool\n",
    "\n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "\n",
    "@dataclass\n",
    "class LinkGroup:\n",
    "    exclusive: bool\n",
    "    required: bool\n",
    "    subgroup: List[dict]\n",
    "\n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "def create_core_metadata_link(child_name: str) -> dict:\n",
    "    link_obj = LinkObj(\n",
    "        name=f\"core_metadata_collections\",\n",
    "        backref=f\"{child_name}s\",\n",
    "        label=None,\n",
    "        target_type=\"core_metadata_collection\",\n",
    "        multiplicity=\"one_to_one\",\n",
    "        required=True \n",
    "    )\n",
    "    return link_obj.to_dict()\n",
    "\n",
    "def convert_entity_links(links: dict, entity_file: bool = False) -> dict:\n",
    "    link_list = []\n",
    "    for link in links:\n",
    "        link_obj = LinkObj(\n",
    "            name=f\"{link['parent']}s\",\n",
    "            backref=f\"{link['child']}s\",\n",
    "            label=None,\n",
    "            target_type=link['parent'],\n",
    "            multiplicity=link['multiplicity'],\n",
    "            required=True  # TODO remove this hard code later, should pull from input yaml\n",
    "        )\n",
    "        link_list.append(link_obj.to_dict())\n",
    "\n",
    "    if entity_file:\n",
    "        core_link = create_core_metadata_link(links[0]['child'])\n",
    "        link_list.append(core_link)\n",
    "\n",
    "    if len(link_list) > 1:\n",
    "        group = LinkGroup(\n",
    "            exclusive=False,\n",
    "            required=True,\n",
    "            subgroup=link_list\n",
    "        )\n",
    "        output = group.to_dict()\n",
    "    else:\n",
    "        output = link_list\n",
    "    return output\n",
    "\n",
    "### Note to self, you will now need to find a way to add in the _definitions and _terms references.\n",
    "### You also need to define a standard for the _definitions and _terms references files to read from as templates\n",
    "\n",
    "def get_properties(entity_name: str, data: Any) -> list[dict]:\n",
    "    output = []\n",
    "    ent = get_entity_data(entity_name, data)\n",
    "    props = ent.properties\n",
    "    if props:\n",
    "        for prop in props:\n",
    "            pdict = {\n",
    "                prop.name: {k: v for k, v in prop.model_dump().items() if k != \"name\"}\n",
    "            }\n",
    "            output.append(pdict)\n",
    "    else:\n",
    "        raise Exception(f'No properties found for entity {entity_name}')\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_category(entity_name: str, data: Any) -> str:\n",
    "    ent = get_entity_data(entity_name, data)\n",
    "    category = ent.category\n",
    "    # If it's an Enum, get its value; otherwise, return as is\n",
    "    if hasattr(category, \"value\"):\n",
    "        return category.value\n",
    "    return category\n",
    "\n",
    "def get_entity_value(entity_name: str, key: str, data: Any):\n",
    "    \"\"\"\n",
    "    Returns the value of a single key within an entity object.\n",
    "\n",
    "    Args:\n",
    "        entity_name (str): The name of the entity to retrieve.\n",
    "        key (str): The key whose value is to be returned.\n",
    "        data (Any): The data structure containing entities.\n",
    "\n",
    "    Returns:\n",
    "        The value associated with the specified key in the entity object.\n",
    "    \"\"\"\n",
    "    ent = get_entity_data(entity_name, data)\n",
    "    return ent.model_dump()[key]\n",
    "\n",
    "\n",
    "def populate_template(entity_name: str, input_data, template) -> dict:\n",
    "    \"\"\"\n",
    "    Populate a Gen3 schema template dictionary with values from a Pydantic data model.\n",
    "\n",
    "    This function takes an entity name, a Pydantic model instance containing entity data,\n",
    "    and a Gen3 schema template dictionary. It fills a copy of the template with values\n",
    "    from the input data, applying special logic for certain keys (e.g., 'name', 'category',\n",
    "    'properties', 'links'). If a key from the input data is not found in the template,\n",
    "    it is added with a value of None and a warning is logged.\n",
    "\n",
    "    Args:\n",
    "        entity_name (str): The name of the entity to populate in the template.\n",
    "        input_data: A Pydantic model instance containing the entity's data.\n",
    "        template (dict): A Gen3 schema template dictionary to be populated.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new Gen3 schema template dictionary populated with values from the input data.\n",
    "\n",
    "    Side Effects:\n",
    "        Logs a warning if a key from the input data is not found in the template.\n",
    "    \"\"\"\n",
    "    # ... function body ...\n",
    "    ent = get_entity_data(entity_name, input_data)\n",
    "    ent_dict = ent.model_dump()\n",
    "    output_schema = template.copy()\n",
    "    \n",
    "    # Checking if entity is file category\n",
    "    file_cat = False\n",
    "    if get_entity_value(entity_name, 'category', input_data) == 'file':\n",
    "        file_cat = True\n",
    "    \n",
    "    for key, value in ent_dict.items():\n",
    "        if key == 'name':\n",
    "            output_schema['id'] = value\n",
    "        elif key == 'category':\n",
    "            output_schema[key] = get_category(entity_name, input_data)\n",
    "        elif key == 'properties':\n",
    "            output_schema[key] = get_properties(entity_name, input_data)\n",
    "        elif key == 'links':\n",
    "            links = get_entity_links(entity_name, input_data)\n",
    "            output_schema[key] = convert_entity_links(links, entity_file=file_cat)\n",
    "        elif key in output_schema:\n",
    "            output_schema[key] = value\n",
    "        else:\n",
    "            logger.warning(f\"Key '{key}' not found in template\")\n",
    "    return output_schema\n",
    "\n",
    "validated_model = DataModel.model_validate(data)\n",
    "# links = get_entity_links('lipidomics_file', validated_model)\n",
    "# convert_entity_links(links, entity_file=True)\n",
    "# get_properties('sample', validated_model)\n",
    "# get_category('sample', validated_model)\n",
    "\n",
    "out_template = populate_template('lipidomics_file', validated_model, converter_template)\n",
    "out_template\n",
    "# write_yaml(out_template, 'output.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3abe1d",
   "metadata": {},
   "source": [
    "# Testing converter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a14aa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 17:30:53,292 [INFO] Successfully loaded YAML file: ../src/gen3schemadev/schema/gen3_metaschema.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 17:30:53,305 [INFO] Successfully loaded YAML file: ../tests/input_example.yml\n",
      "2025-10-01 17:30:53,314 [INFO] Successfully wrote YAML file: output.yml\n"
     ]
    }
   ],
   "source": [
    "from gen3schemadev.schema.gen3_template import *\n",
    "from gen3schemadev.utils import *\n",
    "from gen3schemadev.schema.input_schema import DataModel\n",
    "from gen3schemadev.converter import *\n",
    "\n",
    "\n",
    "\n",
    "# Loading template and metaschema\n",
    "metaschema_path = \"../src/gen3schemadev/schema/gen3_metaschema.yml\"\n",
    "converter_template = generate_gen3_template(metaschema_path)\n",
    "\n",
    "# loading input example\n",
    "data = load_yaml('../tests/input_example.yml')\n",
    "validated_model = DataModel.model_validate(data)\n",
    "\n",
    "\n",
    "out_template = populate_template('lipidomics_file', validated_model, converter_template)\n",
    "write_yaml(out_template, 'output.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93c476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 13:19:17,501 [INFO] Successfully loaded YAML file: ../tests/input_example.yml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([{'sample_id': {'type': 'string',\n",
       "    'description': 'Sample ID (string)',\n",
       "    'enums': None}},\n",
       "  {'sample_count': {'type': 'integer',\n",
       "    'description': 'Number of aliquots (integer)',\n",
       "    'enums': None}},\n",
       "  {'sample_volume': {'type': 'number',\n",
       "    'description': 'Volume in microliters (number/float)',\n",
       "    'enums': None}},\n",
       "  {'is_viable': {'type': 'boolean',\n",
       "    'description': 'Is the sample viable? (boolean)',\n",
       "    'enums': None}},\n",
       "  {'collection_date': {'type': 'datetime',\n",
       "    'description': 'Date and time of collection (datetime)',\n",
       "    'enums': None}},\n",
       "  {'sample_tube_type': {'type': 'enum',\n",
       "    'description': 'Sample tube type (enum)',\n",
       "    'enums': [{'name': 'EDTA'}, {'name': 'Heparin'}, {'name': 'Citrate'}]}},\n",
       "  {'notes': {'type': 'string',\n",
       "    'description': 'Free text notes (string)',\n",
       "    'enums': None}}],\n",
       " ['sample_id', 'collection_date'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gen3schemadev.schema.gen3_template import *\n",
    "from gen3schemadev.utils import *\n",
    "from gen3schemadev.schema.input_schema import DataModel\n",
    "from gen3schemadev.converter import *\n",
    "\n",
    "data = load_yaml('../tests/input_example.yml')\n",
    "validated_model = DataModel.model_validate(data)\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "def strip_required_field(props_list: list[dict]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Remove the 'required' field from all property dicts in the input list.\n",
    "    Can use the output of get_properties() for this function\n",
    "\n",
    "    Args:\n",
    "        props_list (list): A list of property dictionaries, where each dictionary has a single key\n",
    "            (the property name) and its value is a dictionary describing the property. For example:\n",
    "                [\n",
    "                    {\n",
    "                        \"project_id\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"Synthetic_Dataset_1\",\n",
    "                            \"required\": True,\n",
    "                            \"enums\": None\n",
    "                        }\n",
    "                    },\n",
    "                    ...\n",
    "                ]\n",
    "\n",
    "    Returns:\n",
    "        list: A new list with the same structure as props_list, but with the 'required'\n",
    "            field removed from each property's dictionary (if present).\n",
    "\n",
    "    Note:\n",
    "        This function expects a list of property definitions as typically returned by\n",
    "        get_properties() in the Gen3 schema conversion workflow.\n",
    "        If you are working with a DataSourceProtocol object, you should first extract the\n",
    "        properties list using the appropriate function.\n",
    "    \"\"\"\n",
    "    new_list = []\n",
    "    for prop in props_list:\n",
    "        if isinstance(prop, dict):\n",
    "            # Each prop is {property_name: property_dict}\n",
    "            new_prop = {}\n",
    "            for k, v in prop.items():\n",
    "                if isinstance(v, dict):\n",
    "                    v = {key: val for key, val in v.items() if key != 'required'}\n",
    "                new_prop[k] = v\n",
    "            new_list.append(new_prop)\n",
    "        else:\n",
    "            new_list.append(prop)\n",
    "    return new_list\n",
    "\n",
    "def get_required_prop_names(props_list: list[dict]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Given a list of property dicts (as from get_properties), return a list of property names\n",
    "    where the property dict has 'required': True.\n",
    "\n",
    "    Args:\n",
    "        props_list (list): List of property dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of property names with required True.\n",
    "    \"\"\"\n",
    "    required_names = []\n",
    "    for prop in props_list:\n",
    "        if isinstance(prop, dict):\n",
    "            for k, v in prop.items():\n",
    "                if isinstance(v, dict) and v.get(\"required\") is True:\n",
    "                    required_names.append(k)\n",
    "    return required_names\n",
    "\n",
    "project_props = get_properties('sample', validated_model)\n",
    "stripped_props = strip_required_field(project_props)\n",
    "required_names = get_required_prop_names(project_props)\n",
    "stripped_props, required_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2c83ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 16:35:46,694 [WARNING] No properties found for entity lipidomics_file\n",
      "2025-09-30 16:35:46,695 [WARNING] No properties found for entity lipidomics_file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'samples': {'$ref': '_definitions.yaml#/one_to_many'},\n",
       " 'assays': {'$ref': '_definitions.yaml#/one_to_many'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_properties('lipidomics_file', validated_model)\n",
    "construct_props('lipidomics_file', validated_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4b42cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entity(name='lipidomics_file', description='Info about lipidomics file', category=<CategoryEnum.DATA_FILE: 'data_file'>, properties=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entity_data('lipidomics_file', validated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19335da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = get_entity_links('lipidomics_file', validated_model)\n",
    "convert_entity_links(links, entity_file=True)\n",
    "get_entity_value('lipidomics_file', 'category', validated_model) == 'data_file'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226c5de",
   "metadata": {},
   "source": [
    "***\n",
    "## Trying to create template from metaschema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc80133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen3schemadev.schema.gen3_template import *\n",
    "\n",
    "out_template = generate_gen3_template('../src/gen3schemadev/schema/gen3_metaschema.yml')\n",
    "\n",
    "write_yaml(out_template, 'output.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1325f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '_definitions',\n",
       " 'UUID': {'term': {'$ref': '_terms.yaml#/UUID'},\n",
       "  'type': 'string',\n",
       "  'pattern': '^[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}$'},\n",
       " 'parent_uuids': {'type': 'array',\n",
       "  'minItems': 1,\n",
       "  'items': {'$ref': '#/UUID'},\n",
       "  'uniqueItems': True},\n",
       " 'foreign_key_project': {'type': 'object',\n",
       "  'additionalProperties': True,\n",
       "  'properties': {'id': {'$ref': '#/UUID'}, 'code': {'type': 'string'}}},\n",
       " 'to_one_project': {'anyOf': [{'type': 'array',\n",
       "    'items': {'$ref': '#/foreign_key_project', 'minItems': 1, 'maxItems': 1}},\n",
       "   {'$ref': '#/foreign_key_project'}]},\n",
       " 'to_many_project': {'anyOf': [{'type': 'array',\n",
       "    'items': {'$ref': '#/foreign_key_project', 'minItems': 1}},\n",
       "   {'$ref': '#/foreign_key_project'}]},\n",
       " 'foreign_key': {'type': 'object',\n",
       "  'additionalProperties': True,\n",
       "  'properties': {'id': {'$ref': '#/UUID'},\n",
       "   'submitter_id': {'type': 'string'}}},\n",
       " 'to_one': {'anyOf': [{'type': 'array',\n",
       "    'items': {'$ref': '#/foreign_key', 'minItems': 1, 'maxItems': 1}},\n",
       "   {'$ref': '#/foreign_key'}]},\n",
       " 'to_many': {'anyOf': [{'type': 'array',\n",
       "    'items': {'$ref': '#/foreign_key', 'minItems': 1}},\n",
       "   {'$ref': '#/foreign_key'}]},\n",
       " 'datetime': {'oneOf': [{'type': 'string', 'format': 'date-time'},\n",
       "   {'type': 'null'}],\n",
       "  'term': {'$ref': '_terms.yaml#/datetime'}},\n",
       " 'file_name': {'type': 'string', 'term': {'$ref': '_terms.yaml#/file_name'}},\n",
       " 'file_size': {'type': 'integer', 'term': {'$ref': '_terms.yaml#/file_size'}},\n",
       " 'file_format': {'type': 'string',\n",
       "  'term': {'$ref': '_terms.yaml#/file_format'}},\n",
       " 'md5sum': {'type': 'string',\n",
       "  'pattern': '^[a-f0-9]{32}$',\n",
       "  'term': {'$ref': '_terms.yaml#/md5sum'}},\n",
       " 'object_id': {'type': 'string',\n",
       "  'description': 'The GUID of the object in the index service.'},\n",
       " 'release_state': {'description': 'Release state of an entity.',\n",
       "  'default': 'unreleased',\n",
       "  'enum': ['unreleased', 'released', 'redacted']},\n",
       " 'data_bundle_state': {'description': 'State of a data bundle.',\n",
       "  'default': 'submitted',\n",
       "  'enum': ['submitted',\n",
       "   'validated',\n",
       "   'error',\n",
       "   'released',\n",
       "   'suppressed',\n",
       "   'redacted']},\n",
       " 'data_file_error_type': {'term': {'$ref': '_terms.yaml#/data_file_error_type'},\n",
       "  'enum': ['file_size', 'file_format', 'md5sum']},\n",
       " 'state': {'term': {'$ref': '_terms.yaml#/state'},\n",
       "  'default': 'validated',\n",
       "  'downloadable': ['uploaded',\n",
       "   'md5summed',\n",
       "   'validating',\n",
       "   'validated',\n",
       "   'error',\n",
       "   'invalid',\n",
       "   'released'],\n",
       "  'public': ['live'],\n",
       "  'oneOf': [{'enum': ['uploading',\n",
       "     'uploaded',\n",
       "     'md5summing',\n",
       "     'md5summed',\n",
       "     'validating',\n",
       "     'error',\n",
       "     'invalid',\n",
       "     'suppressed',\n",
       "     'redacted',\n",
       "     'live']},\n",
       "   {'enum': ['validated', 'submitted', 'released']}]},\n",
       " 'file_state': {'term': {'$ref': '_terms.yaml#/file_state'},\n",
       "  'default': 'registered',\n",
       "  'enum': ['registered',\n",
       "   'uploading',\n",
       "   'uploaded',\n",
       "   'validating',\n",
       "   'validated',\n",
       "   'submitted',\n",
       "   'processing',\n",
       "   'processed',\n",
       "   'released',\n",
       "   'error']},\n",
       " 'qc_metrics_state': {'term': {'$ref': '_terms.yaml#/qc_metric_state'},\n",
       "  'enum': ['FAIL', 'PASS', 'WARN']},\n",
       " 'project_id': {'type': 'string', 'term': {'$ref': '_terms.yaml#/project_id'}},\n",
       " 'data_file_properties': {'$ref': '#/ubiquitous_properties',\n",
       "  'file_name': {'$ref': '#/file_name'},\n",
       "  'file_size': {'$ref': '#/file_size'},\n",
       "  'md5sum': {'$ref': '#/md5sum'},\n",
       "  'file_state': {'$ref': '#/file_state'},\n",
       "  'object_id': {'$ref': '#/object_id'},\n",
       "  'state': {'$ref': '#/state'},\n",
       "  'error_type': {'$ref': '#/data_file_error_type'}},\n",
       " 'workflow_properties': {'$ref': '#/ubiquitous_properties',\n",
       "  'workflow_link': {'description': 'Link to Github hash for the CWL workflow used.',\n",
       "   'type': 'string'},\n",
       "  'workflow_version': {'description': 'Major version for a GDC workflow.',\n",
       "   'type': 'string'},\n",
       "  'workflow_start_datetime': {'$ref': '#/datetime'},\n",
       "  'workflow_end_datetime': {'$ref': '#/datetime'}},\n",
       " 'ubiquitous_properties': {'type': {'type': 'string'},\n",
       "  'id': {'$ref': '#/UUID', 'systemAlias': 'node_id'},\n",
       "  'submitter_id': {'type': ['string'],\n",
       "   'description': 'A project-specific identifier for a node. This property is the calling card/nickname/alias for a unit of submission. It can be used in place of the UUID for identifying or recalling a node.\\n'},\n",
       "  'state': {'$ref': '#/state'},\n",
       "  'project_id': {'$ref': '#/project_id'},\n",
       "  'created_datetime': {'$ref': '#/datetime'},\n",
       "  'updated_datetime': {'$ref': '#/datetime'}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gen3schemadev.schema.gen3_template import *\n",
    "generate_def_template()\n",
    "# generate_setting_template()\n",
    "# generate_terms_template()\n",
    "# generate_core_metadata_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb81d1",
   "metadata": {},
   "source": [
    "# Testing yaml to bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87fd68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 11:23:37,745 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/demographic.yaml\n",
      "2025-10-03 11:23:37,753 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/project.yaml\n",
      "2025-10-03 11:23:37,756 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/acknowledgement.yaml\n",
      "2025-10-03 11:23:37,759 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/medical_history.yaml\n",
      "2025-10-03 11:23:37,770 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/_definitions.yaml\n",
      "2025-10-03 11:23:37,772 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/_settings.yaml\n",
      "2025-10-03 11:23:37,773 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/program.yaml\n",
      "2025-10-03 11:23:37,777 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/sample.yaml\n",
      "2025-10-03 11:23:37,853 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/_terms.yaml\n",
      "2025-10-03 11:23:37,856 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/lipidomics_file.yaml\n",
      "2025-10-03 11:23:37,858 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/publication.yaml\n",
      "2025-10-03 11:23:37,861 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/subject.yaml\n",
      "2025-10-03 11:23:37,865 [INFO] Successfully loaded YAML file: ../examples/schema/yaml/core_metadata_collection.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'$schema': 'http://json-schema.org/draft-04/schema#',\n",
       " 'id': 'subject',\n",
       " 'title': 'Subject',\n",
       " 'type': 'object',\n",
       " 'namespace': 'http://commons.heartdata.baker.edu.au/',\n",
       " 'category': 'clinical',\n",
       " 'program': '*',\n",
       " 'project': '*',\n",
       " 'description': 'An individual participant in the study with baseline measurements.',\n",
       " 'additionalProperties': False,\n",
       " 'submittable': True,\n",
       " 'validators': None,\n",
       " 'systemProperties': ['id',\n",
       "  'project_id',\n",
       "  'state',\n",
       "  'created_datetime',\n",
       "  'updated_datetime'],\n",
       " 'links': [{'name': 'projects',\n",
       "   'backref': 'subjects',\n",
       "   'label': 'part_of',\n",
       "   'target_type': 'project',\n",
       "   'multiplicity': 'many_to_one',\n",
       "   'required': True}],\n",
       " 'required': ['type', 'submitter_id', 'projects', 'baseline_year'],\n",
       " 'uniqueKeys': [['id'], ['project_id', 'submitter_id']],\n",
       " 'properties': {'$ref': '_definitions.yaml#/ubiquitous_properties',\n",
       "  'projects': {'$ref': '_definitions.yaml#/to_one_project'},\n",
       "  'consent_codes': {'description': 'Data Use Restrictions that are used to indicate  permissions/restrictions for datasets and/or materials, and relates to the purposes for which datasets and/or material might be removed, stored or used. \\\\n\\n        Based on the Data Use Ontology : see http://www.obofoundry.org/ontology/duo.html',\n",
       "   'type': 'array'},\n",
       "  'baseline_year': {'description': 'year when baseline measurements were taken',\n",
       "   'type': 'string'},\n",
       "  'cohort_id': {'description': 'Identifier for the cohort the subject is a part of',\n",
       "   'type': 'string'}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gen3schemadev.utils import bundle_yamls\n",
    "\n",
    "bundle_yamls('../examples/schema/yaml')['subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ced05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../examples/schema/yaml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"../examples/schema/yaml/acknowledgement.yaml\"\n",
    "\n",
    "os.path.dirname(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d9c05",
   "metadata": {},
   "source": [
    "# Working on validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e41fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 10:43:04,324 [INFO] Successfully loaded JSON file: ../output/test_schema_bundle.json\n",
      "2025-10-07 10:43:04,331 [INFO] Validating 'project' with metaschema\n",
      "2025-10-07 10:43:04,506 [INFO] Validating '_definitions' with metaschema\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project\n",
      "_definitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 10:43:04,678 [ERROR] check-jsonschema failed with exit code 1\n",
      "2025-10-07 10:43:04,678 [ERROR] STDOUT: Schema validation errors were encountered.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'title' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'type' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'category' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'program' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'project' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'description' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'submittable' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'validators' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'systemProperties' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'uniqueKeys' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'links' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'required' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpr6890yh7.json::$: 'properties' is a required property\n",
      "\n",
      "2025-10-07 10:43:04,679 [INFO] Validating '' with metaschema\n",
      "2025-10-07 10:43:04,848 [ERROR] check-jsonschema failed with exit code 1\n",
      "2025-10-07 10:43:04,848 [ERROR] STDOUT: Schema validation errors were encountered.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'id' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'title' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'type' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'category' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'program' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'project' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'description' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'submittable' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'validators' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'systemProperties' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'uniqueKeys' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'links' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'required' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpnw_niffy.json::$: 'properties' is a required property\n",
      "\n",
      "2025-10-07 10:43:04,849 [INFO] Validating 'sample' with metaschema\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 10:43:05,012 [ERROR] check-jsonschema failed with exit code 1\n",
      "2025-10-07 10:43:05,012 [ERROR] STDOUT: Schema validation errors were encountered.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpjzaet6m8.json::$.properties.sample_tube_type.type: 'enum' is not valid under any of the given schemas\n",
      "  Underlying errors caused this.\n",
      "\n",
      "  Best Match:\n",
      "    $.properties.sample_tube_type.type: 'enum' is not one of ['array', 'boolean', 'integer', 'null', 'number', 'object', 'string']\n",
      "\n",
      "  1 other errors were produced. Use '--verbose' to see all errors.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpjzaet6m8.json::$.properties.collection_date.type: 'datetime' is not valid under any of the given schemas\n",
      "  Underlying errors caused this.\n",
      "\n",
      "  Best Match:\n",
      "    $.properties.collection_date.type: 'datetime' is not one of ['array', 'boolean', 'integer', 'null', 'number', 'object', 'string']\n",
      "\n",
      "  1 other errors were produced. Use '--verbose' to see all errors.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpjzaet6m8.json::$.links[0]: {'name': 'projects', 'backref': 'samples', 'label': None, 'target_type': 'project', 'multiplicity': 'one_to_many', 'required': True} is not valid under any of the given schemas\n",
      "  Underlying errors caused this.\n",
      "\n",
      "  Best Match:\n",
      "    $.links[0]: Additional properties are not allowed ('backref', 'label', 'multiplicity', 'name', 'target_type' were unexpected)\n",
      "  Best Deep Match:\n",
      "    $.links[0].label: None is not of type 'string'\n",
      "\n",
      "  2 other errors were produced. Use '--verbose' to see all errors.\n",
      "\n",
      "2025-10-07 10:43:05,013 [INFO] Validating '_terms' with metaschema\n",
      "2025-10-07 10:43:05,180 [ERROR] check-jsonschema failed with exit code 1\n",
      "2025-10-07 10:43:05,181 [ERROR] STDOUT: Schema validation errors were encountered.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'title' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'type' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'category' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'program' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'project' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'description' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'submittable' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'validators' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'systemProperties' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'uniqueKeys' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'links' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'required' is a required property\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpgnfrrho8.json::$: 'properties' is a required property\n",
      "\n",
      "2025-10-07 10:43:05,181 [INFO] Validating 'lipidomics_file' with metaschema\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_terms\n",
      "lipidomics_file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 10:43:05,368 [ERROR] check-jsonschema failed with exit code 1\n",
      "2025-10-07 10:43:05,368 [ERROR] STDOUT: Schema validation errors were encountered.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmp4k3lggk8.json::$.links: {'exclusive': False, 'required': True, 'subgroup': [{'name': 'samples', 'backref': 'lipidomics_files', 'label': None, 'target_type': 'sample', 'multiplicity': 'one_to_many', 'required': True}, {'name': 'assays', 'backref': 'lipidomics_files', 'label': None, 'target_type': 'assay', 'multiplicity': 'one_to_many', 'required': True}, {'name': 'core_metadata_collections', 'backref': 'lipidomics_files', 'label': None, 'target_type': 'core_metadata_collection', 'multiplicity': 'one_to_one', 'required': True}]} is not of type 'array'\n",
      "\n",
      "2025-10-07 10:43:05,368 [INFO] Validating 'assay' with metaschema\n",
      "2025-10-07 10:43:05,543 [ERROR] check-jsonschema failed with exit code 1\n",
      "2025-10-07 10:43:05,543 [ERROR] STDOUT: Schema validation errors were encountered.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpyo0vsol2.json::$.links: {'exclusive': False, 'required': True, 'subgroup': [{'name': 'samples', 'backref': 'assays', 'label': None, 'target_type': 'sample', 'multiplicity': 'many_to_one', 'required': True}, {'name': 'core_metadata_collections', 'backref': 'assays', 'label': None, 'target_type': 'core_metadata_collection', 'multiplicity': 'one_to_one', 'required': True}]} is not of type 'array'\n",
      "\n",
      "2025-10-07 10:43:05,544 [INFO] Validating 'core_metadata_collection' with metaschema\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assay\n",
      "core_metadata_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 10:43:05,734 [ERROR] check-jsonschema failed with exit code 1\n",
      "2025-10-07 10:43:05,735 [ERROR] STDOUT: Schema validation errors were encountered.\n",
      "  /var/folders/h1/smw4rryj4zs361v4bw9qqc0c0000gn/T/tmpa4illzze.json::$.properties['$ref']: '_definitions.yaml#/ubiquitous_properties' is not of type 'object'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gen3schemadev.utils import *\n",
    "from gen3schemadev.schema.gen3_template import get_metaschema\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "def bundled_schema_to_dict_list(file: str, return_aux: bool = False):\n",
    "    \"\"\"\n",
    "    Reads a bundled Gen3 JSON schema file and returns a list of schema dictionaries.\n",
    "\n",
    "    Args:\n",
    "        file (str): Path to the bundled JSON file containing multiple schemas.\n",
    "        return_aux (bool): If True, return only the auxiliary schemas (definitions/settings/terms).\n",
    "                           If False, return only the main entity schemas.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of schema dictionaries extracted from the bundled file.\n",
    "    \"\"\"\n",
    "    bundled = read_json(file)\n",
    "    schema_list = []\n",
    "    aux_list = []\n",
    "    aux_schema_names = ['_definitions.yaml', '_settings.yaml', '_terms.yaml']\n",
    "    for k, v in bundled.items():\n",
    "        if k in aux_schema_names:\n",
    "            aux_list.append(v)\n",
    "        else:\n",
    "            schema_list.append(v)\n",
    "\n",
    "    if return_aux:\n",
    "        return aux_list\n",
    "    else:\n",
    "        return schema_list\n",
    "\n",
    "\n",
    "import jsonschema\n",
    "\n",
    "def validate_schema_with_metaschema(schema, metaschema=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Validate a JSON Schema against a metaschema using the check-jsonschema CLI tool.\n",
    "\n",
    "    This function writes the provided schema and metaschema to temporary files and\n",
    "    invokes the external `check-jsonschema` command-line tool to perform validation.\n",
    "\n",
    "    Args:\n",
    "        schema (dict): The JSON Schema to validate.\n",
    "        metaschema (dict, optional): The metaschema to validate against.\n",
    "            If None, you must provide a metaschema explicitly.\n",
    "\n",
    "    Raises:\n",
    "        subprocess.CalledProcessError: If the check-jsonschema command fails.\n",
    "\n",
    "    Returns:\n",
    "        None. Raises an error if validation fails, otherwise completes silently.\n",
    "\n",
    "    Note:\n",
    "        This function does not return a value. It will raise an error if validation fails.\n",
    "        It is intended for use in environments where the check-jsonschema CLI is available.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Validating '{schema.get('id', '')}' with metaschema\")\n",
    "    # Create temp files for schema and metaschema\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as schema_file, \\\n",
    "         tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as metaschema_file:\n",
    "        json.dump(schema, schema_file)\n",
    "        schema_file.flush()\n",
    "        json.dump(metaschema, metaschema_file)\n",
    "        metaschema_file.flush()\n",
    "        schema_path = schema_file.name\n",
    "        metaschema_path = metaschema_file.name\n",
    "    \n",
    "    if verbose:\n",
    "        cmd = [\n",
    "            \"check-jsonschema\", \"--verbose\",\n",
    "            \"--schemafile\", metaschema_path,\n",
    "            schema_path\n",
    "        ]\n",
    "    else:\n",
    "        cmd = [\n",
    "            \"check-jsonschema\",\n",
    "            \"--schemafile\", metaschema_path,\n",
    "            schema_path\n",
    "        ]\n",
    "    # Capture output and wait for the subprocess to complete before returning\n",
    "    completed_process = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if completed_process.returncode != 0:\n",
    "        logger.error(f\"check-jsonschema failed with exit code {completed_process.returncode}\")\n",
    "        # Log stdout/stderr if available\n",
    "        if completed_process.stdout:\n",
    "            logger.error(f\"STDOUT: {completed_process.stdout}\")\n",
    "        if completed_process.stderr:\n",
    "            logger.error(f\"STDERR: {completed_process.stderr}\")\n",
    "        # Do not raise an error, just return\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "schema_list = bundled_schema_to_dict_list('../output/test_schema_bundle.json')\n",
    "metaschema = get_metaschema()\n",
    "\n",
    "for schema in schema_list:\n",
    "    print(schema.get('id', ''))\n",
    "    validate_schema_with_metaschema(schema, metaschema=metaschema, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb38baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$schema': 'http://json-schema.org/draft-04/schema#',\n",
       " 'version': None,\n",
       " 'id': 'sample',\n",
       " 'title': 'sample',\n",
       " 'type': 'object',\n",
       " 'namespace': None,\n",
       " 'category': 'clinical',\n",
       " 'program': '*',\n",
       " 'project': '*',\n",
       " 'description': 'Info about sample',\n",
       " 'submittable': True,\n",
       " 'validators': None,\n",
       " 'systemProperties': ['id',\n",
       "  'project_id',\n",
       "  'state',\n",
       "  'created_datetime',\n",
       "  'updated_datetime'],\n",
       " 'uniqueKeys': [['id'], ['project_id', 'submitter_id']],\n",
       " 'required': ['sample_id', 'collection_date'],\n",
       " 'links': [{'name': 'projects',\n",
       "   'backref': 'samples',\n",
       "   'label': None,\n",
       "   'target_type': 'project',\n",
       "   'multiplicity': 'one_to_many',\n",
       "   'required': True}],\n",
       " 'properties': {'sample_id': {'type': 'string',\n",
       "   'description': 'Sample ID (string)',\n",
       "   'enums': None},\n",
       "  'sample_count': {'type': 'integer',\n",
       "   'description': 'Number of aliquots (integer)',\n",
       "   'enums': None},\n",
       "  'sample_volume': {'type': 'number',\n",
       "   'description': 'Volume in microliters (number/float)',\n",
       "   'enums': None},\n",
       "  'is_viable': {'type': 'boolean',\n",
       "   'description': 'Is the sample viable? (boolean)',\n",
       "   'enums': None},\n",
       "  'collection_date': {'type': 'datetime',\n",
       "   'description': 'Date and time of collection (datetime)',\n",
       "   'enums': None},\n",
       "  'sample_tube_type': {'type': 'enum',\n",
       "   'description': 'Sample tube type (enum)',\n",
       "   'enums': [{'name': 'EDTA'}, {'name': 'Heparin'}, {'name': 'Citrate'}]},\n",
       "  'notes': {'type': 'string',\n",
       "   'description': 'Free text notes (string)',\n",
       "   'enums': None},\n",
       "  'projects': {'$ref': '_definitions.yaml#/one_to_many'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3013c469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38022521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
